export const metadata = {
  title: "Arbeitsplan Masterarbeit (Einf√ºhrung)",
  excerpt: "Mein Plan f√ºr die Organisation der Masterarbeit",
  coverImage: "/img/Blog_Einfuehrung_3/Titelbild.png",
  date: "2025-05-22T12:00:00.000Z",
  author: {
    name: "Claude Widmer",
    picture: "/img/Blog1_2/0.jpg"
  },
  tags: ["Masterarbeit"]
}

# Arbeitsplan Masterarbeit

In diesem Blogbeitrag stelle ich meinen geplanten Arbeitsablauf f√ºr die Masterarbeit vor.

Im Folgenden findest du einen visuellen Arbeitsplan mit den wichtigsten Schritten:
<div className="timeline-legend">
  <b>Legende:</b><br />
  <span></span> üü¢: Erstes Modell erstellt<br />
  <span></span> üü°: Modell in Erarbeitung<br />
  <span></span> üü†: Noch nicht begonnen
</div>


<div className="timeline-container">

  <div className="timeline-step">
    <div className="timeline-number">1</div>
    <div className="timeline-box">
      <b>Erarbeitung eines Modells (Raster) f√ºr die Modellierung des Raumes üü¢ </b><br />
      Wo kann man durchlaufen? Erstellung eines Rasters als Grundlage f√ºr die weitere Analyse.
    </div>
  </div>

  <div className="timeline-step">
    <div className="timeline-number">2</div>
    <div className="timeline-box">
      <b>Feature-Erkennung & Geolokalisierung</b>
      <ul>

        <li><b>2.0:</b> Mapillary Data Retrieval - Wie kann man √ºber eine Million Bilder vom Mapillary herunterladen und verarbeiten? üü† -> üü¢</li>

        <li><b>2.1:</b> YOLO Image Recognition ‚Äì Was ist auf den Bildern zu sehen? Verschiedene Versionen werden getestet.üü¢</li>

        <li><b>2.2:</b> Depth Estimation ‚Äì Erstellung einer Tiefenkarte.üü° -> üü¢</li>

        <li><b>2.3:</b> Zusammenf√ºhrung & Geolokalisierung der in 2.1 gefundenen Features mithilfe der Bildkoordinaten und der Tiefenkarte aus 2.2. üü† -> üü¢</li>
      </ul>
    </div>
  </div>

  <div className="timeline-step">
    <div className="timeline-number">3</div>
    <div className="timeline-box">
      <b>Klassifizierung der Features auf Schulwegsicherheitüü†</b><br />
      Anwendung von ML-Methoden oder Bewertung anhand von Literatur.
    </div>
  </div>

  <div className="timeline-step">
    <div className="timeline-number">4</div>
    <div className="timeline-box">
      <b>Webkarten-Integrationüü† -> üü° (Serverseitig fertig)</b><br />
      Integration der Ergebnisse in eine Webkarte (z.B. QGIS Web Client 2, ArcGIS, etc.).<br />
      <i>Hinweis: Einsatz von Docker zur Bereitstellung der Webanwendung.üü° -> üü¢</i>
    </div>
  </div>

</div>


<hr />

# Arbeitsplan Masterarbeit (Detailansicht)

<div className="multi-stage">

  {/* 1 ‚Äì Rastermodell */}
  <div className="main-stage">
    <div className="main-title">1. Erarbeitung eines Modells (Raster)</div>
    <div className="main-input">
      <>
        <strong>Input:</strong>
        <ul>
          <li>Bounding Box von Z√ºrich</li>
        </ul>
      </>
    </div>

    <div className="sub-steps">
      <div className="sub-box">
        <div className="sub-title">1.1 Raster-Erstellung</div>
        <div className="sub-detail">
          <>
            <strong>Input:</strong>
            <ul><li>wird erg√§nzt</li></ul>
          </>
        </div>
        <div className="sub-detail">
          <>
            <strong>Algorithmus:</strong>
            <ul><li>wird erg√§nzt</li></ul>
          </>
        </div>
        <div className="sub-detail">
          <>
            <strong>Output:</strong>
            <ul><li>wird erg√§nzt</li></ul>
          </>
        </div>
      </div>
    </div>

    <div className="main-output">
      <>
        <strong>Output:</strong>
        <ul><li>wird erg√§nzt</li></ul>
      </>
    </div>
  </div>

  {/* 2 ‚Äì Feature-Erkennung & Geolokalisierung */}
  <div className="main-stage">
    <div className="main-title">2. Feature-Erkennung & Geolokalisierung</div>
    <div className="main-input">
      <>
        <strong>Input:</strong>
        <ul>
          <li>Bounding Box von Z√ºrich</li>
          <li>Mapillary API Token(s)</li>
          <li>Stammverzeichnis (z.‚ÄØB. <code>ROOT_PATH = ./</code>)</li>
        </ul>
      </>
    </div>

    <div className="sub-steps">

      <div className="sub-box">
        <div className="sub-title">2.0 Mapillary Data Retrieval</div>
                
        <div className="sub-detail">
          <>
          <img src="/img/Blog_Einfuehrung_3/2_0_Image.png" alt="Blog Einf√ºhrung 3 - Bild 2.0" style={{ width: '100%', height: 'auto', maxWidth: '400px' }} />
          </>
        </div>
        <div className="sub-detail">
          <>
            <strong>Input:</strong>
            <ul>
              <li><code>Bounding Box</code> von Z√ºrich</li>
              <li><code>GPKG_PATH = ./data/images_bbox_fullmeta.gpkg</code></li>
              <li>Spalte <code>thumb_1024_url</code> mit 1024p-URLs</li>
              <li><code>LAPLACIAN_THRESHOLD</code>: Threshold f√ºr die Bildunsch√§rfen-Erkennung (100)</li>
            </ul>
          </>
        </div>
        <div className="sub-detail">
          <>
            <strong>Algorithmus:</strong>
            <ul>
              <li><strong>Laden von Geodaten:</strong> Das Notebook l√§dt Geodaten und Metadaten √ºber die Mapillary API herunter (√ºber 1,2 Millionen Bilder) und bereitet sie f√ºr die Analyse vor.</li>
              <li><strong>Erkennung von unscharfen Bildern:</strong> Es √ºberpr√ºft die Bildqualit√§t, um unscharfe Bilder zu identifizieren via Laplacian Methode (mit einem Threshold).</li>
              <li><strong>Zuordnung der Ergebnisse:</strong> Die Ergebnisse der Unsch√§rfepr√ºfung werden den Bildern zugeordnet.</li>
              <li><strong>Speichern der Daten:</strong> Die aktualisierten Geodaten werden in einer neuen GeoPackage-Datei gespeichert.</li>
            </ul>
          </>
        </div>
        <div className="sub-detail">
          <>
            <strong>Output:</strong>
            <ul>
              <li><strong> Geopackage </strong> mit allen Metadaten von den 1.2 Millionen Bildern und die Information, ob das Bild unscharf ist.</li>
            </ul>
          </>
        </div>
      </div>

<div className="sub-box">
  <div className="sub-title">2.1 YOLO Image Recognition Training</div>
          <div className="sub-detail">
          <>
          <img src="/img/Blog_Einfuehrung_3/2_1_Image.png" alt="Blog Einf√ºhrung 3 - Bild 2.1" style={{ width: '100%', height: 'auto', maxWidth: '400px' }} />
          </>
        </div>
  <div className="sub-detail">
    <>
      <strong>Input:</strong>
      <ul>
        <li>Mapillary Segmentation and Object Detection Dataset</li>
        <li>YOLO-kompatible Labeldateien (YOLOv8 Format)</li>
      </ul>
    </>
  </div>
  <div className="sub-detail">
    <>
      <strong>Algorithmus:</strong>
      <ul>
        <li>Laden von Trainings- und Validierungsdaten aus YOLO-kompatiblen Pfaden</li>
        <li>Verwendung eines YOLOv8-Medium-Modells (<code>yolo11m-seg.pt</code>) mit vortrainierten Gewichten</li>
        <li>Durchf√ºhrung eines Segmentierungs- und Objekterkennungs-Trainings mit Mixed Precision (AMP)</li>
        <li>Anwendung von Transfer Learning und Feinjustierung √ºber 100+ Epochen mit Early Stopping</li>
        <li>Optimizer automatisch gew√§hlt (AdamW) mit automatischer Lernratenanpassung</li>
        <li>Evaluation nach jeder Epoche mit mAP, Precision und Recall</li>
        <li>Training und Vergleich unterschiedlicher Modellgr√∂ssen (n, s, m, l)</li>
        <li>√úber 12‚ÄØStunden Trainingszeit f√ºr das Medium-Modell, insgesamt √ºber 48‚ÄØStunden zur Modellevaluierung (RTX 4080, 64‚ÄØGB RAM)</li>
      </ul>
    </>
  </div>
  <div className="sub-detail">
    <>
      <strong>Output:</strong>
      <ul>
        <li>Trainiertes YOLO-Modell (<code>best.pt</code>)</li>
        <li>Evaluationsmetriken (Precision, Recall, mAP50, mAP50-95)</li>
        <li>Trainingsplots und Ergebnisvisualisierungen</li>
      </ul>
    </>
  </div>
<div className="sub-detail">
  <>
    <strong>Probleme:</strong>
    <ul>
      <li>Aufgrund des sehr grossen Datensatzes (√ºber 18'000 Bilder) konnte nicht der gesamte Umfang f√ºr das Training genutzt werden.</li>
      <li>Die verf√ºgbare Rechenleistung (GPU/VRAM) war limitiert, was zu kleineren Batchgr√∂ssen und k√ºrzeren Trainingszeiten f√ºhrte.</li>
      <li>Dadurch litt insbesondere der <strong>Recall</strong> (Erkennungsrate), da das Modell viele Objekte nicht zuverl√§ssig detektierte.</li>
      <li>Zus√§tzlich erschwerten die grosse Klassenvielfalt und unbalancierte Verteilung die Generalisierung.</li>
    </ul>
  </>
</div>
</div>

<div className="sub-box">
  <div className="sub-title">2.2 Depth Estimation Processing</div>
  <div className="sub-detail">
    <>
    <img src="/img/Blog_Einfuehrung_3/2_2_Image.png" alt="Blog Einf√ºhrung 3 - Bild 2.2" style={{ width: '100%', height: 'auto', maxWidth: '400px' }} />
    </>
  </div>
  <div className="sub-detail">
    <>
      <strong>Input:</strong>
      <ul>
        <li>Die 1.2 Millionen Bilder vom Schritt 2.0</li>
        <li>Pfadliste aller validen Bilder (vorvalidiert via PIL)</li>
      </ul>
    </>
  </div>
  <div className="sub-detail">
    <>
      <strong>Algorithmus:</strong>
      <ul>
        <li>Scannen aller .jpg-Dateien im Datensatzordner</li>
        <li>Parallelvalidierung mittels PIL, um defekte Bilder zu filtern</li>
        <li>Reduktion der Bildaufl√∂sung (50‚ÄØ%) zur Performance-Optimierung</li>
        <li>Batchweise Tiefensch√§tzung mittels <code>depth-anything</code> Pipeline (HuggingFace)</li>
        <li>Optionales Invertieren der Tiefenwerte f√ºr GIS-Konsistenz</li>
        <li>Export der Tiefendaten als .npz (komprimiert, float16)</li>
        <li>Optional: Export von Tiefenbildern und Histogrammen zur visuellen Kontrolle</li>
        <li>Speicherbereinigung und GPU-Freigabe nach jeder Batch f√ºr stabile Laufzeit</li>
      </ul>
    </>
  </div>
  <div className="sub-detail">
    <>
      <strong>Output:</strong>
      <ul>
        <li>Tiefenkarten im .npz-Format (komprimiert, float16)</li>
        <li>Optional: Visualisierungen der Tiefenbilder (.png)</li>
        <li>Optional: Histogramme der Tiefenverteilung pro Bild</li>
        <li>Gespeichert im Unterordner <code>depth_processed/</code></li>
      </ul>
    </>
  </div>
  <div className="sub-detail">
    <>
      <strong>Probleme:</strong>
      <ul>
        <li>Volle Aufl√∂sung f√ºhrte zu Out-of-Memory-Fehlern ‚Üí Downscaling n√∂tig</li>
        <li>Einige Bilder konnten trotz vorheriger Validierung nicht verarbeitet werden (Pipeline-Fehler)</li>
        <li>Speicherfreigabe und Garbage Collection war n√∂tig, um GPU-Nutzung stabil zu halten</li>
        <li>Laufzeit von √ºber 12‚ÄØStunden f√ºr alle Bilder (RTX 4080, 64‚ÄØGB RAM, 128er Batch-Gr√∂sse)</li>
        <li>Hohe Modellqualit√§t, aber keine Echtzeitverarbeitung m√∂glich</li>
      </ul>
    </>
  </div>
</div>


      <div className="sub-box">
        <div className="sub-title">2.3 Zusammenf√ºhrung & Geolokalisierung</div>
        <div className="sub-detail">
          <>
            <strong>Input:</strong>
            <ul><li>wird erg√§nzt</li></ul>
          </>
        </div>
        <div className="sub-detail">
          <>
            <strong>Algorithmus:</strong>
            <ul><li>wird erg√§nzt</li></ul>
          </>
        </div>
        <div className="sub-detail">
          <>
            <strong>Output:</strong>
            <ul><li>wird erg√§nzt</li></ul>
          </>
        </div>
      </div>

    </div>

    <div className="main-output">
      <>
        <strong>Output:</strong>
        <ul><li>wird erg√§nzt</li></ul>
      </>
    </div>
  </div>

</div>
